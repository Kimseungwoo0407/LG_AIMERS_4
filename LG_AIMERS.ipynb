{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "991f97d7-20c9-4fb2-a918-409b614db085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from gensim.models import Word2Vec\n",
    "import tqdm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbda2ff-64d0-47ba-86b5-0c51a70d43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\") # 학습용 데이터\n",
    "df_test = pd.read_csv(\"submission.csv\") # 테스트 데이터(제출파일의 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f23c89-2b69-4ab3-a33b-fca46e132312",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_to_country = {\n",
    "    'LGEAF': 'Nigeria',\n",
    "    'LGEAG': 'Austria',\n",
    "    'LGEAP': 'Australia',\n",
    "    'LGEAR': 'Argentina',\n",
    "    'LGEAS': 'Algeria',\n",
    "    'LGEBN': 'Netherlands',\n",
    "    'LGEBT': 'Portugal',\n",
    "    'LGECB': 'Colombia',\n",
    "    'LGECH': 'China',\n",
    "    'LGECI': 'Canada',\n",
    "    'LGECL': 'Chile',\n",
    "    'LGECZ': 'Czech',\n",
    "    'LGEDG': 'Germany',\n",
    "    'LGEIN': 'Indonesia',\n",
    "    'LGEIR': 'Iran',\n",
    "    'LGEIS': 'Italy',\n",
    "    'LGEJP': 'Japan',\n",
    "    'LGEKR': 'Korea',\n",
    "    'LGELA': 'Latvia',\n",
    "    'LGELF': 'Jordan',\n",
    "    'LGEMC': 'Morocco',\n",
    "    'LGEMK': 'Hungary',\n",
    "    'LGEML': 'Malaysia',\n",
    "    'LGEMS': 'Mexico',\n",
    "    'LGEPH': 'Philippines',\n",
    "    'LGEPL': 'Poland',\n",
    "    'LGEPR': 'Peru',\n",
    "    'LGEPS': 'Guatemala',\n",
    "    'LGEPT': 'Portugal',\n",
    "    'LGERA': 'Russia',\n",
    "    'LGERO': 'Romania',\n",
    "    'LGESA': 'South Africa',\n",
    "    'LGESJ': 'Saudi Arabia',\n",
    "    'LGESL': 'Singapore',\n",
    "    'LGESP': 'Brazil',\n",
    "    'LGETH': 'Thailand',\n",
    "    'LGETK': 'Turkey',\n",
    "    'LGETT': 'Taiwan',\n",
    "    'LGEUK': 'United Kingdom',\n",
    "    'LGEUR': 'Ukraine',\n",
    "    'LGEUS': 'United States',\n",
    "    'LGEVH': 'Vietnam',\n",
    "    'LGEYK': 'Israel',\n",
    "    'LGESW': 'Denmark',\n",
    "    'LGEIL': 'India',\n",
    "    'LGEGF': 'U.A.E',\n",
    "    'LGEEG': 'Egypt',\n",
    "    'LGEEF': 'Ethiopia',\n",
    "    'LGEES': 'Spain',\n",
    "    'LGEHK': 'Hong Kong',\n",
    "    'LGEHS': 'Greece',\n",
    "    'LGEFS': 'France',\n",
    "    'LGEEB': 'Switzerland'\n",
    "}\n",
    "\n",
    "df_train['response_corporate_1'] = df_train['response_corporate'].map(corp_to_country)\n",
    "df_test['response_corporate_1'] = df_test['response_corporate'].map(corp_to_country)\n",
    "\n",
    "country_to_continent = {\n",
    "    'Nigeria': 'Africa',\n",
    "    'Austria': 'Europe',\n",
    "    'Australia': 'Oceania',\n",
    "    'Argentina': 'South America',\n",
    "    'Algeria': 'Africa',\n",
    "    'Netherlands': 'Europe',\n",
    "    'Portugal': 'Europe',\n",
    "    'Colombia': 'South America',\n",
    "    'China': 'Asia',\n",
    "    'Canada': 'North America',\n",
    "    'Chile': 'South America',\n",
    "    'Czech': 'Europe',\n",
    "    'Germany': 'Europe',\n",
    "    'Indonesia': 'Asia',\n",
    "    'Iran': 'Asia',\n",
    "    'Italy': 'Europe',\n",
    "    'Japan': 'Asia',\n",
    "    'Korea': 'Asia',\n",
    "    'Latvia': 'Europe',\n",
    "    'Jordan': 'Asia',\n",
    "    'Morocco': 'Africa',\n",
    "    'Hungary': 'Europe',\n",
    "    'Malaysia': 'Asia',\n",
    "    'Mexico': 'North America',\n",
    "    'Philippines': 'Asia',\n",
    "    'Poland': 'Europe',\n",
    "    'Peru': 'South America',\n",
    "    'Guatemala': 'North America',\n",
    "    'Russia': 'Europe',\n",
    "    'Romania': 'Europe',\n",
    "    'South Africa': 'Africa',\n",
    "    'Saudi Arabia': 'Asia',\n",
    "    'Singapore': 'Asia',\n",
    "    'Brazil': 'South America',\n",
    "    'Thailand': 'Asia',\n",
    "    'Turkey': 'Asia',\n",
    "    'Taiwan': 'Asia',\n",
    "    'United Kingdom': 'Europe',\n",
    "    'Ukraine': 'Europe',\n",
    "    'United States': 'North America',\n",
    "    'Vietnam': 'Asia',\n",
    "    'Israel': 'Asia',\n",
    "    'Denmark': 'Europe',\n",
    "    'India': 'Asia',\n",
    "    'U.A.E': 'Asia',\n",
    "    'Egypt': 'Africa',\n",
    "    'Ethiopia': 'Africa',\n",
    "    'Spain': 'Europe',\n",
    "    'Hong Kong': 'Asia',\n",
    "    'Greece': 'Europe',\n",
    "    'France': 'Europe',\n",
    "    'Switzerland': 'Europe'\n",
    "}\n",
    "df_train['customer_country.1'] = df_train['response_corporate'].map(country_to_continent)\n",
    "df_test['customer_country.1'] = df_test['response_corporate'].map(country_to_continent)\n",
    "\n",
    "\n",
    "df_train['business_area'] = df_train['business_area'].fillna(df_train.groupby('bant_submit')['business_area'].transform(lambda x: x.mode().iloc[0]))\n",
    "\n",
    "# Fill NaN values in 'business_subarea' with the mode of each 'another_column'\n",
    "df_train['business_subarea'] = df_train['business_subarea'].fillna(df_train.groupby('bant_submit')['business_subarea'].transform(lambda x: x.mode().iloc[0]))\n",
    "\n",
    "df_test['business_area'] = df_test['business_area'].fillna(df_test.groupby('bant_submit')['business_area'].transform(lambda x: x.mode().iloc[0]))\n",
    "\n",
    "# Fill NaN values in 'business_subarea' with the mode of each 'another_column'\n",
    "df_test['business_subarea'] = df_test['business_subarea'].fillna(df_test.groupby('bant_submit')['business_subarea'].transform(lambda x: x.mode().iloc[0]))\n",
    "\n",
    "customeridx_counts = df_train['customer_idx'].value_counts()\n",
    "df_train['customer_idx_freq'] = df_train['customer_idx'].apply(lambda x: customeridx_counts[x])\n",
    "df_test['customer_idx_freq'] = df_test['customer_idx'].apply(lambda x: customeridx_counts.get(x, 0))\n",
    "\n",
    "lead_owner_counts = df_train['lead_owner'].value_counts()\n",
    "df_train['lead_owner_freq'] = df_train['lead_owner'].apply(lambda x: lead_owner_counts[x])\n",
    "df_test['lead_owner_freq'] = df_test['lead_owner'].apply(lambda x: lead_owner_counts.get(x, 0))\n",
    "\n",
    "response_corporate_counts = df_train['response_corporate'].value_counts()\n",
    "df_train['response_corporate_freq'] = df_train['response_corporate'].apply(lambda x: response_corporate_counts[x])\n",
    "df_test['response_corporate_freq'] = df_test['response_corporate'].apply(lambda x: response_corporate_counts.get(x, 0))\n",
    "\n",
    "most_frequent = df_train['customer_country'].mode()[0]\n",
    "df_train['customer_country'].fillna(most_frequent, inplace=True)\n",
    "df_test['customer_country'].fillna(most_frequent, inplace = True)\n",
    "\n",
    "def fillna_with_mode(x):\n",
    "    mode_value = x.mode()\n",
    "    if mode_value.empty:\n",
    "        return x\n",
    "    else:\n",
    "        return x.fillna(mode_value[0])\n",
    "\n",
    "df_train['customer_type'] = df_train.groupby('customer_idx')['customer_type'].transform(fillna_with_mode)\n",
    "df_test['customer_type'] = df_test.groupby('customer_idx')['customer_type'].transform(fillna_with_mode)\n",
    "\n",
    "# 학습 데이터에서 'enterprise' 범주별 평균 계산\n",
    "enterprise_mean = df_train.groupby('enterprise')['historical_existing_cnt'].mean()\n",
    "\n",
    "# 결측치 처리 함수 정의                                                                           #추가\n",
    "def fillna_by_enterprise_mean(row):\n",
    "    if pd.isnull(row['historical_existing_cnt']):\n",
    "        return enterprise_mean[row['enterprise']]\n",
    "    else:\n",
    "        return row['historical_existing_cnt']\n",
    "\n",
    "df_train['historical_existing_cnt'].fillna(-1, inplace=True)\n",
    "\n",
    "# 학습 데이터에서 적용한 동일한 변환을 테스트 데이터에 적용\n",
    "df_test['historical_existing_cnt'].fillna(-1, inplace=True)\n",
    "\n",
    "#ver_win_rate_x 중앙값을 계산\n",
    "mean_per_bu = df_train.groupby('bant_submit')['ver_win_rate_x'].median()\n",
    "\n",
    "# ver_win_rate_x NA 값을 해당 bant_submit 평균값으로 채움\n",
    "df_train['ver_win_rate_x'].fillna(df_train['bant_submit'].map(mean_per_bu), inplace=True)\n",
    "\n",
    "# 학습 데이터에서 계산한 평균값을 테스트 데이터의 결측치에 적용\n",
    "df_test['ver_win_rate_x'].fillna(df_test['bant_submit'].map(mean_per_bu), inplace=True)\n",
    "\n",
    "#ver_win_ratio_per_bu의 중앙값을 계산\n",
    "mean_per_bu = df_train.groupby('business_unit')['ver_win_ratio_per_bu'].median()\n",
    "\n",
    "# ver_win_ratio_per_bu의 NA 값을 해당 business_unit의 평균값으로 채움\n",
    "df_train['ver_win_ratio_per_bu'].fillna(df_train['business_unit'].map(mean_per_bu), inplace=True)\n",
    "\n",
    "# 학습 데이터에서 계산한 중앙값을 테스트 데이터의 결측치에 적용\n",
    "df_test['ver_win_ratio_per_bu'].fillna(df_test['business_unit'].map(mean_per_bu), inplace=True)\n",
    "\n",
    "# Calculate the average value of ver_win_ratio_per_bu grouped by bant_submit\n",
    "mean_per_bant_submit = df_train.groupby('bant_submit')['ver_win_ratio_per_bu'].median()\n",
    "\n",
    "# Fill the NA value of ver_win_ratio_per_bu with the average value of the corresponding bant_submit\n",
    "df_train['ver_win_ratio_per_bu'].fillna(df_train['bant_submit'].map(mean_per_bant_submit), inplace=True)\n",
    "\n",
    "# Apply the average value calculated from the training data to the missing values of the test data\n",
    "df_test['ver_win_ratio_per_bu'].fillna(df_test['bant_submit'].map(mean_per_bant_submit), inplace=True)\n",
    "\n",
    "#ver_win_ratio_per_bu의 평균값을 계산\n",
    "mean_per_bu = df_train.groupby('business_unit')['com_reg_ver_win_rate'].mean()\n",
    "\n",
    "# ver_win_ratio_per_bu의 NA 값을 해당 business_unit의 평균값으로 채움\n",
    "df_train['com_reg_ver_win_rate'].fillna(df_train['business_unit'].map(mean_per_bu), inplace=True)\n",
    "\n",
    "# 학습 데이터에서 계산한 평균값을 테스트 데이터의 결측치에 적용\n",
    "df_test['com_reg_ver_win_rate'].fillna(df_test['business_unit'].map(mean_per_bu), inplace=True)\n",
    "\n",
    "#com_reg_ver_win_rate 평균값을 계산\n",
    "mean_per_submit = df_train.groupby('bant_submit')['com_reg_ver_win_rate'].mean()\n",
    "\n",
    "# com_reg_ver_win_rate NA 값을 해당 business_unit의 평균값으로 채움\n",
    "df_train['com_reg_ver_win_rate'].fillna(df_train['bant_submit'].map(mean_per_submit), inplace=True)\n",
    "\n",
    "# 학습 데이터에서 계산한 평균값을 테스트 데이터의 결측치에 적용\n",
    "df_test['com_reg_ver_win_rate'].fillna(df_test['bant_submit'].map(mean_per_submit), inplace=True)\n",
    "\n",
    "df_train['historical_conversion_rate_per_customer'] = df_train['historical_existing_cnt'] / df_train.groupby('customer_idx')['historical_existing_cnt'].transform('sum')\n",
    "\n",
    "df_test['historical_conversion_rate_per_customer'] = df_test['historical_existing_cnt'] / df_test.groupby('customer_idx')['historical_existing_cnt'].transform('sum')\n",
    "\n",
    "mean_conversion_rate = df_train['historical_conversion_rate_per_customer'].mean()\n",
    "df_train['historical_conversion_rate_per_customer'].fillna(mean_conversion_rate, inplace=True)\n",
    "\n",
    "mean_conversion_rate_ts = df_test['historical_conversion_rate_per_customer'].mean()\n",
    "df_test['historical_conversion_rate_per_customer'].fillna(mean_conversion_rate_ts, inplace=True)\n",
    "\n",
    "mean_conversion_rate = df_train['historical_conversion_rate_per_customer'].mean()\n",
    "df_train['historical_conversion_rate_per_customer'].fillna(mean_conversion_rate, inplace=True)\n",
    "\n",
    "mean_conversion_rate_ts = df_test['historical_conversion_rate_per_customer'].mean()\n",
    "df_test['historical_conversion_rate_per_customer'].fillna(mean_conversion_rate_ts, inplace=True)\n",
    "df_train['product_category'] = df_train['product_category'].fillna(df_train.groupby('business_unit')['product_category'].transform(lambda x: x.mode().iloc[0]))\n",
    "df_test['product_category'] = df_test['product_category'].fillna(df_test.groupby('business_unit')['product_category'].transform(lambda x: x.mode().iloc[0]))\n",
    "\n",
    "df_train['product_subcategory'] = df_train['product_subcategory'].fillna(df_train.groupby('bant_submit')['product_subcategory'].transform(lambda x: x.mode().iloc[0]))\n",
    "df_test['product_subcategory'] = df_test['product_subcategory'].fillna(df_test.groupby('bant_submit')['product_subcategory'].transform(lambda x: x.mode().iloc[0]))\n",
    "df_train['customer_job'] = df_train.groupby('customer_idx')['customer_job'].transform(fillna_with_mode)\n",
    "df_test['customer_job'] = df_test.groupby('customer_idx')['customer_job'].transform(fillna_with_mode)\n",
    "def fillna_with_mode_safe(x):\n",
    "    if x.mode().empty:\n",
    "        return 'Unknown'  # 또는 다른 처리 방법을 선택할 수 있음\n",
    "    else:\n",
    "        return x.mode().iloc[0]\n",
    "\n",
    "df_train['product_modelname'] = df_train['product_modelname'].fillna(df_train.groupby('product_subcategory')['product_modelname'].transform(fillna_with_mode_safe))\n",
    "df_test['product_modelname'] = df_test['product_modelname'].fillna(df_test.groupby('product_subcategory')['product_modelname'].transform(fillna_with_mode_safe))\n",
    "\n",
    "def label_encoding(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"범주형 데이터를 시리즈 형태로 받아 숫자형 데이터로 변환합니다.\"\"\"\n",
    "\n",
    "    my_dict = {}\n",
    "\n",
    "    # 모든 요소를 문자열로 변환\n",
    "    series = series.astype(str)\n",
    "\n",
    "    for idx, value in enumerate(sorted(series.unique())):\n",
    "        my_dict[value] = idx\n",
    "    series = series.map(my_dict)\n",
    "\n",
    "    return series\n",
    "\n",
    "# 레이블 인코딩할 칼럼들\n",
    "label_columns = [\n",
    "    \"customer_country\",\n",
    "    \"business_subarea\",\n",
    "    \"business_area\",\n",
    "    \"business_unit\",\n",
    "    \"customer_type\",\n",
    "    \"enterprise\",\n",
    "    \"customer_job\",\n",
    "    \"inquiry_type\",\n",
    "    \"product_category\",\n",
    "    \"product_subcategory\",\n",
    "    \"product_modelname\",\n",
    "    \"customer_country.1\",\n",
    "    \"customer_position\",\n",
    "    \"response_corporate\",\n",
    "    \"response_corporate_1\",\n",
    "    \"expected_timeline\"\n",
    "]\n",
    "\n",
    "df_all = pd.concat([df_train[label_columns], df_test[label_columns]])\n",
    "\n",
    "for col in label_columns:\n",
    "    df_all[col] = label_encoding(df_all[col])\n",
    "\n",
    "# Cat2Vec 모델 정의 및 학습\n",
    "cat2vec_model = Word2Vec(sentences=df_all[label_columns].values.tolist(), vector_size=100, window=5, min_count=1, workers=4,seed=400)\n",
    "\n",
    "# 모든 벡터의 평균 계산\n",
    "average_vector = np.mean(cat2vec_model.wv.vectors, axis=0)\n",
    "\n",
    "for col in label_columns:\n",
    "    # 범주형 변수의 모든 값에 대한 임베딩을 평균하여 범주형 변수를 임베딩으로 대체\n",
    "    df_all[col] = df_all[col].apply(lambda x: cat2vec_model.wv[x].mean() if x in cat2vec_model.wv else average_vector)\n",
    "\n",
    "for col in label_columns:  \n",
    "    df_train[col] = df_all.iloc[: len(df_train)][col]\n",
    "    df_test[col] = df_all.iloc[len(df_train) :][col]\n",
    "\n",
    "df_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df_train.fillna(df_train.mean(), inplace=True)\n",
    "df_test.fillna(df_test.mean(), inplace=True)\n",
    "\n",
    "df_train.drop(['id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver','ver_cus','ver_pro'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee69e1c-2a87-4367-8faa-ed85e8b0046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "# 피처 데이터와 타겟 데이터를 정의합니다.\n",
    "X = df_train.drop('is_converted', axis=1)\n",
    "y = df_train['is_converted']\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=400)\n",
    "\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2868576-ec60-4aad-b193-9edcdaeb6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991fa86f-09dc-4c13-ba8b-66aab9720fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(scale_pos_weight=8.25,\n",
    "                       learning_rate=0.085, \n",
    "                       num_iterations = 1000, # n_estimator 랑 같은 것 같음\n",
    "                       max_depth = 5,\n",
    "                       num_leaves = 31,\n",
    "                       n_jobs=-1,\n",
    "                       boost_from_average=False,\n",
    "                       objective = 'binary',\n",
    "                       random_state=42)\n",
    "\n",
    "clf = AdaBoostClassifier(estimator = LGBMClassifier(scale_pos_weight = 8.25, \n",
    "                                                         learning_rate = 0.085, \n",
    "                                                         num_iterations = 1000, \n",
    "                                                         max_depth = 5, \n",
    "                                                         num_leaves = 31, \n",
    "                                                         random_state = 42, \n",
    "                                                         n_jobs = -1, \n",
    "                                                         objective = 'binary',\n",
    "                                                        boost_from_average = False),\n",
    "                        n_estimators = 15, learning_rate = 0.001, random_state = 42)\n",
    "\n",
    "clf.fit(x_train.fillna(0), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281d210-53f5-47f3-b998-16c575905073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, y_pred=None):\n",
    "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
    "    \n",
    "    print(\"오차행렬:\\n\", confusion)\n",
    "    print(\"\\n정확도: {:.4f}\".format(accuracy))\n",
    "    print(\"정밀도: {:.4f}\".format(precision))\n",
    "    print(\"재현율: {:.4f}\".format(recall))\n",
    "    print(\"F1: {:.4f}\".format(F1))\n",
    "\n",
    "pred = clf.predict(x_val.fillna(0))\n",
    "get_clf_eval(y_val, pred)\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test.drop([\"is_converted\", \"id\"], axis=1)\n",
    "\n",
    "x_test.drop(['id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver','ver_cus','ver_pro'], axis=1, inplace=True)\n",
    "\n",
    "test_pred = clf.predict(x_test.fillna(0))\n",
    "sum(test_pred) # True로 예측된 개수\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"is_converted\"] = test_pred\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
